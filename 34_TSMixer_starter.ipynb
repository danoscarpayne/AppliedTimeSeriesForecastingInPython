{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3036add-94c7-4065-a1f5-3e7deb3754e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a049981-2569-4b4a-b9bc-807359f249c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "  def __init__(self, batch_size, seq_len, pred_len):\n",
    "    self.batch_size = batch_size\n",
    "    self.seq_len = seq_len\n",
    "    self.pred_len = pred_len\n",
    "    self.target_slice = slice(0, None)\n",
    "\n",
    "    self._read_data()\n",
    "\n",
    "  def _read_data(self):\n",
    "\n",
    "    url = 'https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh1.csv'\n",
    "\n",
    "    df_raw = pd.read_csv(url)\n",
    "    df = df_raw.set_index('date')\n",
    "\n",
    "    # split train/valid/test\n",
    "    n = len(df)\n",
    "    train_end = int(n * 0.7)\n",
    "    val_end = n - int(n * 0.2)\n",
    "    test_end = n\n",
    "\n",
    "    train_df = df[:train_end]\n",
    "    val_df = df[train_end - self.seq_len : val_end]\n",
    "    test_df = df[val_end - self.seq_len : test_end]\n",
    "\n",
    "    # standardize by training set\n",
    "    self.scaler = StandardScaler()\n",
    "    self.scaler.fit(train_df.values)\n",
    "\n",
    "    def scale_df(df, scaler):\n",
    "      data = scaler.transform(df.values)\n",
    "      return pd.DataFrame(data, index=df.index, columns=df.columns)\n",
    "\n",
    "    self.train_df = scale_df(train_df, self.scaler)\n",
    "    self.val_df = scale_df(val_df, self.scaler)\n",
    "    self.test_df = scale_df(test_df, self.scaler)\n",
    "    self.n_feature = self.train_df.shape[-1]\n",
    "\n",
    "  def _split_window(self, data):\n",
    "    inputs = data[:, : self.seq_len, :]\n",
    "    labels = data[:, self.seq_len :, self.target_slice]\n",
    "\n",
    "    inputs.set_shape([None, self.seq_len, None])\n",
    "    labels.set_shape([None, self.pred_len, None])\n",
    "    return inputs, labels\n",
    "\n",
    "  def _make_dataset(self, data, shuffle=True):\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        data=data,\n",
    "        targets=None,\n",
    "        sequence_length=(self.seq_len + self.pred_len),\n",
    "        sequence_stride=1,\n",
    "        shuffle=shuffle,\n",
    "        batch_size=self.batch_size,\n",
    "    )\n",
    "    ds = ds.map(self._split_window)\n",
    "    return ds\n",
    "\n",
    "  def inverse_transform(self, data):\n",
    "    return self.scaler.inverse_transform(data)\n",
    "\n",
    "  def get_train(self, shuffle=True):\n",
    "    return self._make_dataset(self.train_df, shuffle=shuffle)\n",
    "\n",
    "  def get_val(self):\n",
    "    return self._make_dataset(self.val_df, shuffle=False)\n",
    "\n",
    "  def get_test(self):\n",
    "    return self._make_dataset(self.test_df, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c57f3-1312-4021-84ae-c4e26dcb44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val/test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a4018-4730-4fe8-8b9b-6667e291b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# Function to create time and feature mixing layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75090a1e-7c97-48c8-857e-a9530adc8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d66ed-90af-4296-ae01-174f36a8a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd210a-19aa-4e93-a721-ae6556c7b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0eccbe-d5fd-4b60-9282-6601a512dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(history.history['val_loss'])\n",
    "\n",
    "model.load_weights(\"tsmixer_checkpoints/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ffb1d-e53e-4835-a34a-9c5e77b5cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)\n",
    "\n",
    "scaled_preds = predictions[-1,:,:]\n",
    "\n",
    "scaled_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfe8cbe-926f-457c-96b3-93940d6caaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT']\n",
    "\n",
    "scaled_preds_df = pd.DataFrame(scaled_preds)\n",
    "scaled_preds_df.columns = cols\n",
    "\n",
    "# inverse transform the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85497c63-5df0-404a-be70-6d56b04185b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh1.csv')\n",
    "df = df_raw.set_index('date')\n",
    "\n",
    "cols_to_plot = ['OT', 'HULL', 'MUFL', 'MULL']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,8))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    col = cols_to_plot[i]\n",
    "    \n",
    "    ax.plot(df[col][-96:])\n",
    "    ax.plot(preds_df[col], label='TSMixer', ls='--', color='green')\n",
    "    \n",
    "    ax.legend(loc='best')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_title(col)\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(8))\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716d7a99-5ec8-4a84-8309-4e6e07400d25",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358dfd21-fc26-4653-b479-f30bfb2128de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "actual = df[-96:]\n",
    "\n",
    "tsmixer_mae = mean_absolute_error(actual, preds_df) \n",
    "tsmixer_mse = mean_squared_error(actual, preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe98455-3bf6-4941-8dcb-28511260087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tsmixer_mae, tsmixer_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f82bda-b0be-4dd0-b0e8-358fb3528144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
