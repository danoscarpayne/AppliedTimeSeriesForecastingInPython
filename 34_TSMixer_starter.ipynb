{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3036add-94c7-4065-a1f5-3e7deb3754e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a049981-2569-4b4a-b9bc-807359f249c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 11:24:01.142301: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "  def __init__(self, batch_size, seq_len, pred_len):\n",
    "    self.batch_size = batch_size\n",
    "    self.seq_len = seq_len\n",
    "    self.pred_len = pred_len\n",
    "    self.target_slice = slice(0, None)\n",
    "\n",
    "    self._read_data()\n",
    "\n",
    "  def _read_data(self):\n",
    "\n",
    "    url = 'https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh1.csv'\n",
    "\n",
    "    df_raw = pd.read_csv(url)\n",
    "    df = df_raw.set_index('date')\n",
    "\n",
    "    # split train/valid/test\n",
    "    n = len(df)\n",
    "    train_end = int(n * 0.7)\n",
    "    val_end = n - int(n * 0.2)\n",
    "    test_end = n\n",
    "\n",
    "    train_df = df[:train_end]\n",
    "    val_df = df[train_end - self.seq_len : val_end]\n",
    "    test_df = df[val_end - self.seq_len : test_end]\n",
    "\n",
    "    # standardize by training set\n",
    "    self.scaler = StandardScaler()\n",
    "    self.scaler.fit(train_df.values)\n",
    "\n",
    "    def scale_df(df, scaler):\n",
    "      data = scaler.transform(df.values)\n",
    "      return pd.DataFrame(data, index=df.index, columns=df.columns)\n",
    "\n",
    "    self.train_df = scale_df(train_df, self.scaler)\n",
    "    self.val_df = scale_df(val_df, self.scaler)\n",
    "    self.test_df = scale_df(test_df, self.scaler)\n",
    "    self.n_feature = self.train_df.shape[-1]\n",
    "\n",
    "  def _split_window(self, data):\n",
    "    inputs = data[:, : self.seq_len, :]\n",
    "    labels = data[:, self.seq_len :, self.target_slice]\n",
    "\n",
    "    inputs.set_shape([None, self.seq_len, None])\n",
    "    labels.set_shape([None, self.pred_len, None])\n",
    "    return inputs, labels\n",
    "\n",
    "  def _make_dataset(self, data, shuffle=True):\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        data=data,\n",
    "        targets=None,\n",
    "        sequence_length=(self.seq_len + self.pred_len),\n",
    "        sequence_stride=1,\n",
    "        shuffle=shuffle,\n",
    "        batch_size=self.batch_size,\n",
    "    )\n",
    "    ds = ds.map(self._split_window)\n",
    "    return ds\n",
    "\n",
    "  def inverse_transform(self, data):\n",
    "    return self.scaler.inverse_transform(data)\n",
    "\n",
    "  def get_train(self, shuffle=True):\n",
    "    return self._make_dataset(self.train_df, shuffle=shuffle)\n",
    "\n",
    "  def get_val(self):\n",
    "    return self._make_dataset(self.val_df, shuffle=False)\n",
    "\n",
    "  def get_test(self):\n",
    "    return self._make_dataset(self.test_df, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950c57f3-1312-4021-84ae-c4e26dcb44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val/test sets\n",
    "data_loader = DataLoader(batch_size=32, seq_len=512, pred_len=96)\n",
    "\n",
    "train_data = data_loader.get_train()\n",
    "val_data = data_loader.get_val()\n",
    "test_data = data_loader.get_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af8a4018-4730-4fe8-8b9b-6667e291b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# Function to create time and feature mixing layers\n",
    "def res_block(inputs, ff_dim):\n",
    "\n",
    "    norm = layers.BatchNormalization\n",
    "\n",
    "    # time mixing\n",
    "    x = norm(axis=[-2, -1])(inputs)\n",
    "\n",
    "    x = tf.transpose(x, perm=[0,2,1])\n",
    "    x = layers.Dense(x.shape[-1], activation='relu')(x)\n",
    "    x = tf.transpose(x, perm=[0,2,1])\n",
    "    x = layers.Dropout(0.7)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feature scaling\n",
    "    x = norm(axis=[-2,-1])(res)\n",
    "    x = layers.Dense(ff_dim, activation = 'relu')(x)\n",
    "    x = layers.Dropout(0.7)(x)\n",
    "    x = layers.Dense(inputs.shape[-1])(x)\n",
    "    x = layers.Dropout(0.7)(x)\n",
    "\n",
    "    return x + res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75090a1e-7c97-48c8-857e-a9530adc8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the model\n",
    "def build_model(input_shape, pred_len, n_block, ff_dim, target_slice):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    x = inputs\n",
    "    for _ in range(n_block):\n",
    "        x = res_block(x, ff_dim)\n",
    "\n",
    "    if target_slice:\n",
    "        x = x[:, :, target_slice]\n",
    "\n",
    "    # Temporal projection\n",
    "    x = tf.transpose(x, perm=[0,2,1])\n",
    "    x = layers.Dense(pred_len)(x)\n",
    "    outputs = tf.transpose(x, perm=[0,2,1])\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e37d66ed-90af-4296-ae01-174f36a8a5f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_feature\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_block\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mff_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_slice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [20], line 8\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(input_shape, pred_len, n_block, ff_dim, target_slice)\u001b[0m\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_block):\n\u001b[0;32m----> 8\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mres_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mff_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_slice:\n\u001b[1;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[:, :, target_slice]\n",
      "Cell \u001b[0;32mIn [19], line 9\u001b[0m, in \u001b[0;36mres_block\u001b[0;34m(inputs, ff_dim)\u001b[0m\n\u001b[1;32m      6\u001b[0m norm \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mBatchNormalization\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# time mixing\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m(inputs)\n\u001b[1;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtranspose(x, perm\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/flashscore/lib/python3.10/site-packages/keras/src/layers/normalization/batch_normalization.py:144\u001b[0m, in \u001b[0;36mBatchNormalization.__init__\u001b[0;34m(self, axis, momentum, epsilon, center, scale, beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer, beta_regularizer, gamma_regularizer, beta_constraint, gamma_constraint, synchronized, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    127\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    142\u001b[0m ):\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m synchronized \u001b[38;5;129;01mand\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mbackend() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    148\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument synchronized=True is only supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the TensorFlow backend.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'list'"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = build_model(input_shape=(512, data_loader.n_feature), pred_len=96, n_block=8, ff_dim=64, target_slice=data_loader.target_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59111c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd210a-19aa-4e93-a721-ae6556c7b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0eccbe-d5fd-4b60-9282-6601a512dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(history.history['val_loss'])\n",
    "\n",
    "model.load_weights(\"tsmixer_checkpoints/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ffb1d-e53e-4835-a34a-9c5e77b5cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)\n",
    "\n",
    "scaled_preds = predictions[-1,:,:]\n",
    "\n",
    "scaled_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfe8cbe-926f-457c-96b3-93940d6caaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT']\n",
    "\n",
    "scaled_preds_df = pd.DataFrame(scaled_preds)\n",
    "scaled_preds_df.columns = cols\n",
    "\n",
    "# inverse transform the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85497c63-5df0-404a-be70-6d56b04185b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh1.csv')\n",
    "df = df_raw.set_index('date')\n",
    "\n",
    "cols_to_plot = ['OT', 'HULL', 'MUFL', 'MULL']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,8))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    col = cols_to_plot[i]\n",
    "    \n",
    "    ax.plot(df[col][-96:])\n",
    "    ax.plot(preds_df[col], label='TSMixer', ls='--', color='green')\n",
    "    \n",
    "    ax.legend(loc='best')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_title(col)\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(8))\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716d7a99-5ec8-4a84-8309-4e6e07400d25",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358dfd21-fc26-4653-b479-f30bfb2128de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "actual = df[-96:]\n",
    "\n",
    "tsmixer_mae = mean_absolute_error(actual, preds_df) \n",
    "tsmixer_mse = mean_squared_error(actual, preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe98455-3bf6-4941-8dcb-28511260087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tsmixer_mae, tsmixer_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f82bda-b0be-4dd0-b0e8-358fb3528144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
